主要是由于实习做的东西是这个，面试经常问到，所以总结一下。

在业务中，经常需要跑一些定时触发的作业，这些作业会以一定的频率在某个特定时间点处罚，比如每周一0点跑一次。 这时候需要一个有效的调度系统来完成。



自己调研过的分布式定时任务系统 https://zhuanlan.zhihu.com/p/128601558



最终选型方案，参考一些开源框架和linux本身系统设计来实现。



* 延迟队列使用redis内置数据结构zset来实现，再基于时间轮分片的思想，把一天以小时为单位分为24个格子。当配置层新增任务时，判断任务最近执行时间距离现在是否在24h以内，如果是就装入一个zset里，否则先暂存到数据库。
* 时间轮轮转时，把23h以后的任务从数据库装入时间轮里
* 每秒轮询zset头部，把满足下发条件的任务下发到消息队列
* 执行器消费消息





基于redis实现延时队列的考虑：

* 堆 pass，redis本身支持持久化与集群部署，是一个成熟的中间件，简单实用堆对任务排序，需要自己实现持久化
* RabitMQ，这是一种通用方案，通过死信队列的方法，设置消息过期时间，当消息过期后会被路由到一个设置好的队列。但是经过调研发现，消息的过期检测是惰性的，即队列前面的消息没有被消费之前，即使后面的消息先过期了，还是需要等待。
* 时间轮，每个格子直接用链表维护，新增任务时效率低下。进一步改进，设置多级时间轮。那么这种做法其实类似于zset了，本质是引入更加高效的数据结构



综上，决定基于redis实现延时队列。

但是，如果每次收到任务都丢到zset里，未免效率过低，所以选择结束DB，出现小时轮转时，从数据库把任务装载到时间轮。并且使用24个zset更加保证查询和插入的效率，同时这24个zset彼此是独立的，可以集群部署，避免任务过多导致撑爆内存。



对下发器分布式部署，依赖分布式锁。



消息队列选型使用kafka，统一topic，所有执行器位于同一个consumer group。设置多partion，保证负载均衡。

基于kafka是个高吞吐的消息队列，并且容易横向扩展，增加新partion，增加新的topic，增加新的消费者。



在这种设计中，任务下发和执行是完全解耦的，执行器本身无状态，并且完全根据自己的能力执行任务。当任务执行失败，进行重试。仍然失败就丢到新的topic的队列里被其他consumer group的执行器重试。



这种架构设计本身就是去中心化的，因为所有部分都是无状态的。但是用户必须知道所有任务的执行情况。所以对于每次任务执行信息，都会被持久化到数据库，后续如果数据过大可以考虑落ES。



如果执行器挂掉，需要回收正在执行的任务并发送到其他执行器的任务下行通道。同时，下发器之间也要维持心跳，主从备份。

其实kafka有一套机制，只有消费完成，才提交offset，就不怕消息在消费者挂掉以后丢失。



如果数据很大，24个zset也存不下该怎么办？

对zset横向扩展，使用Twemproxy中间件，可以对redis代理分片。

本质上还是负载均衡那套，由代理服务器决定请求落在哪台redis服务器上。根据key做hash然后负载均衡。为了高可用，代理服务器也要集群化。













